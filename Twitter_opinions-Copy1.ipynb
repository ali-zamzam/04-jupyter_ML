{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "608d8726",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rechauffementClimatique.csv\n",
      "tweet.csv\n",
      "tweet1.csv\n",
      "modele_twitter.mod\n",
      "rechauffementClimatique_non_preparees.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib as plt\n",
    "\n",
    "#chargement des stopwords\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "#fonction de normalisation\n",
    "import re\n",
    "\n",
    "#stemmatisation\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "\n",
    "#lemmatization\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "#jeux d'apprentissageet de test\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# desactivation du nombres de colonnes\n",
    "pd.set_option('display.max_columns',None)\n",
    "\n",
    "# recuperation des fichiers\n",
    "\n",
    "listDeFichiers = os.listdir(\"data\")\n",
    "\n",
    "#quel est les noms des fichiers\n",
    "\n",
    "for fichier in listDeFichiers:\n",
    "    print(fichier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c7840763",
   "metadata": {},
   "outputs": [],
   "source": [
    "messagesTwitter = pd.read_csv('data/rechauffementClimatique.csv', sep=';')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a194f6e",
   "metadata": {},
   "source": [
    "### informations sur le nombres d'observations et leur contenu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "02d89a0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4225 entries, 0 to 4224\n",
      "Data columns (total 3 columns):\n",
      " #   Column     Non-Null Count  Dtype  \n",
      "---  ------     --------------  -----  \n",
      " 0   TWEET      4225 non-null   object \n",
      " 1   CROYANCE   4225 non-null   object \n",
      " 2   CONFIENCE  4225 non-null   float64\n",
      "dtypes: float64(1), object(2)\n",
      "memory usage: 99.1+ KB\n"
     ]
    }
   ],
   "source": [
    "messagesTwitter.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "49e533cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TWEET</th>\n",
       "      <th>CROYANCE</th>\n",
       "      <th>CONFIENCE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Global warming report urges governments to act...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Fighting poverty and global warming in Africa ...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Carbon offsets: How a Vatican forest failed to...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0.8786</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               TWEET CROYANCE  CONFIENCE\n",
       "0  Global warming report urges governments to act...      Yes     1.0000\n",
       "1  Fighting poverty and global warming in Africa ...      Yes     1.0000\n",
       "2  Carbon offsets: How a Vatican forest failed to...      Yes     0.8786"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messagesTwitter.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6d5f6144",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TWEET</th>\n",
       "      <th>CROYANCE</th>\n",
       "      <th>CONFIENCE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Global warming report urges governments to act...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Fighting poverty and global warming in Africa ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Carbon offsets: How a Vatican forest failed to...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.8786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Carbon offsets: How a Vatican forest failed to...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>URUGUAY: Tools Needed for Those Most Vulnerabl...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.8087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4220</th>\n",
       "      <td>It's 83•_Á and climbing in NYC. August weather...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4221</th>\n",
       "      <td>@bloodless_coup \"The phrase 'global warming' s...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4222</th>\n",
       "      <td>Global warming you tube parody you will enjoy ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.6411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4223</th>\n",
       "      <td>One-Eyed Golfer: Don't dare tell me about glob...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4224</th>\n",
       "      <td>man made global warming a hair brained theory ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4225 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  TWEET  CROYANCE  CONFIENCE\n",
       "0     Global warming report urges governments to act...         1     1.0000\n",
       "1     Fighting poverty and global warming in Africa ...         1     1.0000\n",
       "2     Carbon offsets: How a Vatican forest failed to...         1     0.8786\n",
       "3     Carbon offsets: How a Vatican forest failed to...         1     1.0000\n",
       "4     URUGUAY: Tools Needed for Those Most Vulnerabl...         1     0.8087\n",
       "...                                                 ...       ...        ...\n",
       "4220  It's 83•_Á and climbing in NYC. August weather...         1     1.0000\n",
       "4221  @bloodless_coup \"The phrase 'global warming' s...         1     1.0000\n",
       "4222  Global warming you tube parody you will enjoy ...         0     0.6411\n",
       "4223  One-Eyed Golfer: Don't dare tell me about glob...         0     1.0000\n",
       "4224  man made global warming a hair brained theory ...         0     1.0000\n",
       "\n",
       "[4225 rows x 3 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messagesTwitter.CROYANCE= (messagesTwitter['CROYANCE']=='Yes').astype(\"int64\")\n",
    "messagesTwitter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80d5974e",
   "metadata": {},
   "source": [
    "# Normalisation\n",
    "<h1> Module Re (Regular expression)</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3d742e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalisation(message):\n",
    "    message = re.sub('((www\\.[^\\s]+)|(https?://[^\\s]+))','URL', message)\n",
    "    message = re.sub('@[^\\s]+','USER', message)\n",
    "    message = message.lower().replace(\"ё\", \"е\")\n",
    "    message = re.sub('[^a-zA-Zа-яА-Я1-9]+', ' ', message)\n",
    "    message = re.sub(' +',' ', message)\n",
    "    return message.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc2fa2f2",
   "metadata": {},
   "source": [
    "## Réaliser la normalisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f068f683",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TWEET</th>\n",
       "      <th>CROYANCE</th>\n",
       "      <th>CONFIENCE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>global warming report urges governments to act...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fighting poverty and global warming in africa ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>carbon offsets how a vatican forest failed to ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.8786</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               TWEET  CROYANCE  CONFIENCE\n",
       "0  global warming report urges governments to act...         1     1.0000\n",
       "1  fighting poverty and global warming in africa ...         1     1.0000\n",
       "2  carbon offsets how a vatican forest failed to ...         1     0.8786"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messagesTwitter.TWEET= messagesTwitter.TWEET.apply(normalisation)\n",
    "messagesTwitter.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38fbfe13",
   "metadata": {},
   "source": [
    "<h2>Étape 2 : suppression des stops words</h2>\n",
    "\n",
    "Pour supprimer les stop words de nos messages en anglais, nous allons utiliser ceux connus par le module nltk.corpus : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "591667ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopword = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "efc921f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import nltk\n",
    "# nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "59449b84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(stopword)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "020a7aec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                  TWEET  CROYANCE  CONFIENCE\n",
      "0     global warming report urges governments act br...         1     1.0000\n",
      "1           fighting poverty global warming africa link         1     1.0000\n",
      "2     carbon offsets vatican forest failed reduce gl...         1     0.8786\n",
      "3     carbon offsets vatican forest failed reduce gl...         1     1.0000\n",
      "4     uruguay tools needed vulnerable climate change...         1     0.8087\n",
      "...                                                 ...       ...        ...\n",
      "4220  83 climbing nyc august weather first day may u...         1     1.0000\n",
      "4221  user phrase global warming abandoned favor cli...         1     1.0000\n",
      "4222     global warming tube parody enjoy ipcc ocra url         0     0.6411\n",
      "4223  one eyed golfer dare tell global warming twent...         0     1.0000\n",
      "4224  man made global warming hair brained theory 4 ...         0     1.0000\n",
      "\n",
      "[4225 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "messagesTwitter['TWEET'] = messagesTwitter['TWEET'].apply(lambda x: ' '.join([mot for mot in x.split() if mot not in (stopword)]))\n",
    "print(messagesTwitter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5929e55",
   "metadata": {},
   "source": [
    "<h2>Étape 3 : le stemming</h2>\n",
    "<p>La stemmisation des messages se fait à l'aide du module nltk et de la classe <b>SnowballStemmer</b>.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8226dcb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TWEET</th>\n",
       "      <th>CROYANCE</th>\n",
       "      <th>CONFIENCE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>global warm report urg govern act brussel belg...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fight poverti global warm africa link</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>carbon offset vatican forest fail reduc global...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.8786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>carbon offset vatican forest fail reduc global...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>uruguay tool need vulner climat chang link</td>\n",
       "      <td>1</td>\n",
       "      <td>0.8087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4220</th>\n",
       "      <td>83 climb nyc august weather first day may unbe...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4221</th>\n",
       "      <td>user phrase global warm abandon favor climat c...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4222</th>\n",
       "      <td>global warm tube parodi enjoy ipcc ocra url</td>\n",
       "      <td>0</td>\n",
       "      <td>0.6411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4223</th>\n",
       "      <td>one eye golfer dare tell global warm twenti fi...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4224</th>\n",
       "      <td>man made global warm hair brain theori 4 scien...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4225 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  TWEET  CROYANCE  CONFIENCE\n",
       "0     global warm report urg govern act brussel belg...         1     1.0000\n",
       "1                 fight poverti global warm africa link         1     1.0000\n",
       "2     carbon offset vatican forest fail reduc global...         1     0.8786\n",
       "3     carbon offset vatican forest fail reduc global...         1     1.0000\n",
       "4            uruguay tool need vulner climat chang link         1     0.8087\n",
       "...                                                 ...       ...        ...\n",
       "4220  83 climb nyc august weather first day may unbe...         1     1.0000\n",
       "4221  user phrase global warm abandon favor climat c...         1     1.0000\n",
       "4222        global warm tube parodi enjoy ipcc ocra url         0     0.6411\n",
       "4223  one eye golfer dare tell global warm twenti fi...         0     1.0000\n",
       "4224  man made global warm hair brain theori 4 scien...         0     1.0000\n",
       "\n",
       "[4225 rows x 3 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmer = SnowballStemmer('english')\n",
    "messagesTwitter['TWEET'] = messagesTwitter['TWEET'].apply(lambda x: ' '.join([stemmer.stem(mot) for mot in x.split() if mot not in (stopword)]))\n",
    "messagesTwitter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60cf5ae8",
   "metadata": {},
   "source": [
    "<h2> Étape 4 : la lemmatisation</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8e2829ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/ubuntu/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7e31a52f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TWEET</th>\n",
       "      <th>CROYANCE</th>\n",
       "      <th>CONFIENCE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>global warm report urg govern act brussel belg...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fight poverti global warm africa link</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>carbon offset vatican forest fail reduc global...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.8786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>carbon offset vatican forest fail reduc global...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>uruguay tool need vulner climat chang link</td>\n",
       "      <td>1</td>\n",
       "      <td>0.8087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4220</th>\n",
       "      <td>83 climb nyc august weather first day may unbe...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4221</th>\n",
       "      <td>user phrase global warm abandon favor climat c...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4222</th>\n",
       "      <td>global warm tube parodi enjoy ipcc ocra url</td>\n",
       "      <td>0</td>\n",
       "      <td>0.6411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4223</th>\n",
       "      <td>one eye golfer dare tell global warm twenti fi...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4224</th>\n",
       "      <td>man made global warm hair brain theori 4 scien...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4225 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  TWEET  CROYANCE  CONFIENCE\n",
       "0     global warm report urg govern act brussel belg...         1     1.0000\n",
       "1                 fight poverti global warm africa link         1     1.0000\n",
       "2     carbon offset vatican forest fail reduc global...         1     0.8786\n",
       "3     carbon offset vatican forest fail reduc global...         1     1.0000\n",
       "4            uruguay tool need vulner climat chang link         1     0.8087\n",
       "...                                                 ...       ...        ...\n",
       "4220  83 climb nyc august weather first day may unbe...         1     1.0000\n",
       "4221  user phrase global warm abandon favor climat c...         1     1.0000\n",
       "4222        global warm tube parodi enjoy ipcc ocra url         0     0.6411\n",
       "4223  one eye golfer dare tell global warm twenti fi...         0     1.0000\n",
       "4224  man made global warm hair brain theori 4 scien...         0     1.0000\n",
       "\n",
       "[4225 rows x 3 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "messagesTwitter['TWEET'] = messagesTwitter['TWEET'].apply(lambda x: ' '.join([lemmatizer.lemmatize(mot) for mot in x.split(' ')]))\n",
    "messagesTwitter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8e82eb4",
   "metadata": {},
   "source": [
    "# phases d'apprentissage et de prédiction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "550d1979",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# #Creation des datas d'apprentissage/validation\n",
    "X_train, X_test, y_train, y_test = train_test_split(messagesTwitter['TWEET'].values, messagesTwitter['CROYANCE'].values, test_size= 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c182657",
   "metadata": {},
   "source": [
    "<h2>2. Création d’un pipeline d’apprentissage</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bab98a68",
   "metadata": {},
   "source": [
    "La première action ajoutée au pipeline va consister, à l’aide de la fonction <b>CountVectorizer(),</b> à créer la matrice des occurrences des différents mots dans les différentes phrases comme nous avons appris à le faire manuellement."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1163c63b",
   "metadata": {},
   "source": [
    "<b>(Terme Frequency )</b>, et à leur nombre d’apparitions dans l’ensemble des messages <b>(Inverse document frequency).</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32295eea",
   "metadata": {},
   "source": [
    "Ce poids appelé <b>TF-IDF </b>sert également à exprimer la rareté du mot dans l’ensemble des messages."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c9de745",
   "metadata": {},
   "source": [
    "le TF-IDF décroît quand un mot est présent dans beaucoup de messages ;<br>\n",
    "\n",
    "le TF-IDF décroît également quand il est peu présent dans un message ;<br>\n",
    "\n",
    "le TF-IDF est maximal pour les mots peu fréquents apparaissant beaucoup dans l’ensemble des messages que nous avons à analyser.<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97e2790f",
   "metadata": {},
   "source": [
    "Le mot \"chien\" apparaît plusieurs fois dans les phrases, son TF-IDF sera faible.<br><br>\n",
    "\n",
    "Les mots \"bleue\" et \"rouge\" apparaissent peu de fois, leur TF-IDF sera faible également.<br><br>\n",
    "\n",
    "Le mot \"balle\" apparaît certes peu de fois dans les deux phrases, mais au moins une fois dans les deux. Sa fréquence (TF) est donc faible, mais il apparaît dans deux phrases (IDF). Son TF-IDF sera donc élevé.<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf17df44",
   "metadata": {},
   "source": [
    "Ex: <br>\n",
    "Le chien joue dehors avec d’autres chiens avec une balle bleue.<br>\n",
    "Le chien et les autres chiens jouent dehors avec une balle rouge.<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea7fda83",
   "metadata": {},
   "source": [
    "Le mot \"chien\" apparaît plusieurs fois dans les phrases, son TF-IDF sera faible.<br><br>\n",
    "\n",
    "Les mots \"bleue\" et \"rouge\" apparaissent peu de fois, leur TF-IDF sera faible également.<br><br>\n",
    "\n",
    "Le mot \"balle\" apparaît certes peu de fois dans les deux phrases, mais au moins une fois dans les deux. Sa fréquence (TF) est donc faible, mais il apparaît dans deux phrases (IDF). Son TF-IDF sera donc élevé.<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c81c8a0",
   "metadata": {},
   "source": [
    "<h1>L e TF_IDF est calculé à l'aide de la fonction TdiTransformer()du module Scikit-Learn</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6914fbe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB # l'algorithme Naive Byes\n",
    "\n",
    "etapes_apprentissage = Pipeline([('frequence',CountVectorizer()),('tfidf', TfidfTransformer()),('algorithme',MultinomialNB())])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "719df559",
   "metadata": {},
   "source": [
    "# 3. Apprentissage et analyse de resultat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "534c85cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "modele = etapes_apprentissage.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0c1e156c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8118    0.3180    0.4570       217\n",
      "           1     0.8053    0.9745    0.8818       628\n",
      "\n",
      "    accuracy                         0.8059       845\n",
      "   macro avg     0.8085    0.6462    0.6694       845\n",
      "weighted avg     0.8069    0.8059    0.7727       845\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, modele.predict(X_test), digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82524189",
   "metadata": {},
   "source": [
    "# 4. Classification d'un nouveau message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9db4498d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data/modele_twitter.mod']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn.externals \n",
    "import joblib\n",
    "fichier = 'data/modele-tw.mod'\n",
    "joblib.dump(modele, fichier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55f890e1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# input\n",
    "message = input(\"veuillez rentrer votre message  \")\n",
    "messagesTwitter = pd.DataFrame(data=message, index=[0], columns=['TWEET'])\n",
    "\n",
    "\n",
    "# normalisation\n",
    "\n",
    "def normalisation(message):\n",
    "    message = re.sub('((www\\.[^\\s]+)|(https?://[^\\s]+))','URL', message)\n",
    "    message = re.sub('@[^\\s]+','USER', message)\n",
    "    message = message.lower().replace(\"ё\", \"е\")\n",
    "    message = re.sub('[^a-zA-Zа-яА-Я1-9]+', ' ', message)\n",
    "    message = re.sub(' +',' ', message)\n",
    "    return message.strip()\n",
    "\n",
    "messagesTwitter.TWEET= messagesTwitter.TWEET.apply(normalisation)\n",
    "messagesTwitter.head(3)\n",
    "\n",
    "# stopword \n",
    "stopword = stopwords.words('english')\n",
    "\n",
    "messagesTwitter['TWEET'] = messagesTwitter['TWEET'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stopword)]))\n",
    "print(messagesTwitter)\n",
    "\n",
    "# stemmer\n",
    "stemmer = SnowballStemmer('english')\n",
    "\n",
    "messagesTwitter['TWEET'] = messagesTwitter['TWEET'].apply(lambda x: ' '.join([stemmer.stem(word) for word in x.split() if word not in (stopword)]))\n",
    "messagesTwitter\n",
    "\n",
    "# lemmatizer\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "messagesTwitter['TWEET'] = messagesTwitter['TWEET'].apply(lambda x: ' '.join([lemmatizer.lemmatize(word) for word in x.split(' ')]))\n",
    "messagesTwitter\n",
    "\n",
    "# prediction\n",
    "\n",
    "prediction = modele.predict(messagesTwitter['TWEET'])\n",
    "\n",
    "if(prediction[0]==0):\n",
    "\n",
    "     print(\">> Ne croit pas au rechauffement climatique…\")\n",
    "\n",
    "else:\n",
    "\n",
    "     print(\">> Croit au rechauffement climatique...\")\n",
    "        \n",
    "        \n",
    "#message : Why should trust scientists with global warming if they didnt know Pluto wasnt a planet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72c899db",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Twitter = pd.read_csv('data/tweet.csv', sep=',')\n",
    "Twitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c1180fc8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ea3093a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
